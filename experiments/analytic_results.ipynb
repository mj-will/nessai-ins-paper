{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analytic & Rosenbrock results\n",
    "\n",
    "Includes the comparison to nessai.\n",
    "\n",
    "Michael J. Williams 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "\n",
    "basedir = \"../\"\n",
    "\n",
    "sys.path.append(basedir)\n",
    "\n",
    "from utils import configure_plotting, load_all_results\n",
    "    \n",
    "configure_plotting(basedir)\n",
    "default_figsize = plt.rcParams[\"figure.figsize\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = './outdir_rerun/'\n",
    "gaussian_path = os.path.join(path, f'ins_gaussian_*d', '')\n",
    "gmm_path = os.path.join(path, f'ins_gmm_paper_*d', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gaussian_results = load_all_results(gaussian_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gmm_results = load_all_results(gmm_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "possible_dims = np.arange(2, 34, 2)\n",
    "truth = {n: -n * np.log(20) for n in possible_dims}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "figsize = ((10 / 13) * default_figsize[0], default_figsize[1] * (1.8 / 5))\n",
    "\n",
    "results = [gaussian_results, gmm_results]\n",
    "hspace = 0.1\n",
    "# Ratio of height to width scaled by the number of subplots in each dimension\n",
    "wspace = hspace * (figsize[1] / figsize[0]) * (2 / 1)\n",
    "\n",
    "fig, axs = plt.subplots(\n",
    "    1, len(results), sharey=True, figsize=figsize,\n",
    "    gridspec_kw={\"hspace\": hspace, \"wspace\": wspace}\n",
    ")\n",
    "\n",
    "offset_width = 0.15\n",
    "offsets = offset_width * (np.arange(len(results)) - (len(results) - 1)/ 2)\n",
    "\n",
    "for i, res in enumerate(results):\n",
    "    dims = np.array(list(res.keys()))\n",
    "    log_z = np.array([d['log_evidence'].mean() - truth[k] for k, d in res.items()])\n",
    "    log_z_err = np.array([d['log_evidence_error'].mean() for d in res.values()])\n",
    "    final_log_z = np.array([d['final_log_evidence'].mean() - truth[k] for k, d in res.items()])\n",
    "    final_log_z_err = np.array([d['final_log_evidence_error'].mean() for d in res.values()])\n",
    "\n",
    "    print(f\"Results for model {i}\")\n",
    "    print(\"log Z: \", log_z)\n",
    "    print(\"final_log Z: \", final_log_z)\n",
    "    print(f\"Average bias: {np.abs(100 * log_z / dims * np.log(20))} %\")\n",
    "    \n",
    "    axs[i].errorbar(dims * (1 + offsets[0]), log_z, yerr=log_z_err, ls='', capsize=3.0, marker='x', label='Initial')\n",
    "    axs[i].errorbar(dims * (1 + offsets[1]), final_log_z, yerr=final_log_z_err, ls='', capsize=3.0, marker='.', label='Resampled')\n",
    "    axs[i].grid(axis='y')\n",
    "    axs[i].set_xlabel('Dimensions')\n",
    "    axs[i].set_xscale(\"log\", base=2)\n",
    "    axs[i].set_xticks(dims)\n",
    "    \n",
    "\n",
    "axs[0].set_title('Gaussian')\n",
    "axs[1].set_title('Gaussian Mixture')\n",
    "axs[0].set_ylabel(r'$\\ln (\\hat{Z} / Z_{\\textrm{True}})$')\n",
    "axs[1].tick_params(labelright=True)\n",
    "  \n",
    "    \n",
    "# h, l = fig.axes[0].get_legend_handles_labels()\n",
    "# fig.legend(h, l, frameon=False, ncol=2, loc='lower center', bbox_to_anchor=(0.6, -0.05))\n",
    "fig.savefig('figures_rerun/resampling.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison to nessai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gaussian_baseline_path = './outdir/baseline_gaussian_*d/'\n",
    "baseline_gaussian_results = load_all_results(\n",
    "    gaussian_baseline_path, file='summary.json'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gmm_baseline_path = './outdir/baseline_gmm_paper_*'\n",
    "baseline_gmm_results = load_all_results(\n",
    "    gmm_baseline_path, file='summary.json'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rosenbrock_path = './outdir_rerun/ins_rosenbrock_*d/'\n",
    "rosenbrock_results = load_all_results(rosenbrock_path, file=\"summary.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rosenbrock_baseline_path = './outdir/baseline_rosenbrock_*d/'\n",
    "baseline_rosenbrock_results = load_all_results(rosenbrock_baseline_path, file=\"summary.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_results = [gaussian_results, gmm_results, rosenbrock_results]\n",
    "all_baselines = [baseline_gaussian_results, baseline_gmm_results, baseline_rosenbrock_results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "references = [\"gaussian\", \"gaussian\", \"ins\"]\n",
    "shift = 0.06\n",
    "quantiles = [0.16, 0.84]\n",
    "\n",
    "n_cols = len(all_results)\n",
    "n_rows = 5\n",
    "\n",
    "\n",
    "figsize = (default_figsize[0], 1.8 * default_figsize[1])\n",
    "hspace = 0.1\n",
    "# Ratio of height to width scaled by the number of subplots in each dimension\n",
    "wspace = hspace * (figsize[1] / figsize[0]) * (n_cols / n_rows)\n",
    "\n",
    "fig, axs = plt.subplots(\n",
    "    n_rows, n_cols,\n",
    "    figsize=figsize,\n",
    "    sharex=\"col\", sharey=\"row\",\n",
    "    gridspec_kw={\"wspace\": wspace, \"hspace\": hspace, \"width_ratios\": [5, 5, 3]}\n",
    ")\n",
    "\n",
    "for (col_idx, results), baseline, ref in zip(enumerate(all_results), all_baselines, references):\n",
    "\n",
    "    dims = np.array(list(results.keys()))\n",
    "    print(\"Found dims\")\n",
    "\n",
    "    def get_mean_std(res, key):\n",
    "        mu = np.array([d[key].mean() for d in res.values()])\n",
    "        std = np.array([d[key].std() for d in res.values()])\n",
    "        # std = np.array([np.quantile(d[key], quantiles) for d in res.values()]).T\n",
    "        # std[0, :] = np.abs(mu - std[0, :])\n",
    "        # std[1, :] = np.abs(std[1, :] - mu)\n",
    "        \n",
    "        return mu, std\n",
    "\n",
    "    evidence = get_mean_std(results, 'final_log_evidence')\n",
    "    baseline_evidence = get_mean_std(baseline, 'log_evidence')\n",
    "\n",
    "    error = get_mean_std(results, 'final_log_evidence_error')\n",
    "    baseline_error = get_mean_std(baseline, 'log_evidence_error')\n",
    "\n",
    "    evals = get_mean_std(results, 'likelihood_evaluations')\n",
    "    baseline_evals = get_mean_std(baseline, 'likelihood_evaluations')\n",
    "\n",
    "    times = get_mean_std(results, 'sampling_time')\n",
    "    baseline_times = get_mean_std(baseline, 'sampling_time')\n",
    "\n",
    "    ess = get_mean_std(results, 'ess')\n",
    "    baseline_ess = get_mean_std(baseline, 'ess')\n",
    "\n",
    "    print('Difference in mean values (ins vs ns)')\n",
    "    print(f'Evidence mean: {evidence[0]} vs {baseline_evidence[0]}')\n",
    "    print(f'Evidence std: {evidence[1]} vs {baseline_evidence[1]}')\n",
    "    print(f'Evals: {evals[0]} vs {baseline_evals[0]}')\n",
    "    print(f'Ratio: {baseline_evals[0] / evals[0]}')\n",
    "    print(f'ESS: {ess[0]} vs {baseline_ess[0]}')\n",
    "\n",
    "    dims_ins = (1 - shift) * dims\n",
    "    dims_ns = (1 + shift) * dims\n",
    "    marker = '.'\n",
    "    ns_marker = 'x'\n",
    "    \n",
    "    label = r'$\\ln (\\hat{Z} / Z_\\textrm{Ref})$'\n",
    "    \n",
    "    if ref == \"gaussian\":\n",
    "        offset = np.array([t for d, t in truth.items() if d in dims])\n",
    "    elif ref == \"ins\":\n",
    "        offset = evidence[0]\n",
    "    elif ref == \"baseline\":\n",
    "        offset = baseline[0]\n",
    "    else:\n",
    "        raise ValueError()\n",
    "    \n",
    "    axs[0, col_idx].errorbar(dims_ins, evidence[0] - offset, yerr=evidence[1], ls='',\n",
    "                    marker=marker)\n",
    "    axs[0, col_idx].errorbar(dims_ns, baseline_evidence[0] - offset, yerr=baseline_evidence[1], \n",
    "                    ls='', marker=ns_marker)\n",
    "\n",
    "    axs[1, col_idx].errorbar(dims_ins, error[0], yerr=error[1], ls='',\n",
    "                    marker=marker)\n",
    "    axs[1, col_idx].errorbar(dims_ns, baseline_error[0], yerr=baseline_error[1], ls='',\n",
    "                    marker=ns_marker)\n",
    "\n",
    "    print(evals[1])\n",
    "    \n",
    "    axs[2, col_idx].errorbar(dims_ins, evals[0], yerr=evals[1], ls='', marker=marker, capsize=3.0)\n",
    "    axs[2, col_idx].errorbar(dims_ns, baseline_evals[0], yerr=baseline_evals[1], ls='', \n",
    "                    marker=ns_marker)\n",
    "    axs[2, col_idx].set_yscale('log')\n",
    "\n",
    "    axs[3, col_idx].errorbar(dims_ins, times[0], yerr=times[1], ls='', marker=marker, capsize=3.0)\n",
    "    axs[3, col_idx].errorbar(dims_ns, baseline_times[0], yerr=baseline_times[1], ls='',\n",
    "                    marker=ns_marker)\n",
    "    axs[3, col_idx].set_yscale('log')\n",
    "\n",
    "    axs[4, col_idx].errorbar(dims_ins, ess[0], yerr=ess[1], ls='', marker=marker, capsize=3.0)\n",
    "    axs[4, col_idx].errorbar(dims_ns, baseline_ess[0], yerr=baseline_ess[1], ls='',\n",
    "                    marker=ns_marker)\n",
    "    \n",
    "    axs[-1, col_idx].set_xlabel('Dimensions')\n",
    "    axs[-1, col_idx].set_xscale('log', base=2)\n",
    "    axs[-1, col_idx].set_xticks(dims.tolist())\n",
    "    \n",
    "axs[0, 0].set_ylabel(label)  \n",
    "axs[1, 0].set_ylabel(r\"$\\sigma [\\ln \\hat{Z}]$\")    \n",
    "axs[2, 0].set_ylabel('Likelihood\\nevaluations')    \n",
    "axs[3, 0].set_ylabel('Wall time [s]')\n",
    "axs[4, 0].set_ylabel('ESS')\n",
    "    \n",
    "for a in axs.flatten():\n",
    "    a.grid(axis='y', which=\"major\")\n",
    "\n",
    "axs[0, 0].set_title(\"Gaussian\")\n",
    "axs[0, 1].set_title(\"Gaussian Mixture\")\n",
    "axs[0, 2].set_title(\"Rosenbrock\")\n",
    "\n",
    "for i in range(n_rows):\n",
    "    axs[i, -1].tick_params(labelright=True)\n",
    "\n",
    "# plt.tight_layout()\n",
    "\n",
    "fig.savefig(\"figures_rerun/comparison_all.pdf\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, sharey=True)\n",
    "key = \"final_log_evidence\"\n",
    "for j, results in enumerate([gaussian_results, gmm_results]):\n",
    "    N = 50\n",
    "    x = np.linspace(0, 1, N)\n",
    "    x_ref = np.linspace(0, 1, 1001)\n",
    "    confidence_interval = [0.68, 0.95, 0.997]\n",
    "    for ci in confidence_interval:\n",
    "        edge_of_bound = (1. - ci) / 2.\n",
    "        lower = stats.binom.ppf(1 - edge_of_bound, N, x_ref) / N\n",
    "        upper = stats.binom.ppf(edge_of_bound, N, x_ref) / N\n",
    "        # The binomial point percent function doesn't always return 0 @ 0,\n",
    "        # so set those bounds explicitly to be sure\n",
    "        lower[0] = 0\n",
    "        upper[0] = 0\n",
    "        axs[j].fill_between(x_ref, lower, upper, alpha=0.1, color='grey')\n",
    "\n",
    "    colours = sns.color_palette(\"mako\", n_colors=5)\n",
    "\n",
    "    for i, (dims, res) in enumerate(results.items()):\n",
    "        Z_hat = np.exp(res[key])\n",
    "        std = np.abs(res[key + \"_error\"] * Z_hat)\n",
    "        dist = stats.norm(loc=np.exp(truth[dims]), scale=np.mean(std))\n",
    "        pp = sm.ProbPlot(Z_hat, dist=dist)\n",
    "        axs[j].plot(x, pp.sample_percentiles, label=dims, c=colours[i])\n",
    "#     axs[j].legend(title=\"Dimensions\")\n",
    "    axs[j].set_xlim([0, 1])\n",
    "    axs[j].set_ylim([0, 1])\n",
    "    axs[j].set(adjustable='box', aspect='equal')\n",
    "axs[0].set_title(\"Gaussian\")\n",
    "axs[1].set_title(\"Gaussian Mixture\")\n",
    "\n",
    "axs[0].set_ylabel(\"Empirical CDF\")\n",
    "axs[0].set_xlabel(\"Theoretical CDF\")\n",
    "axs[1].set_xlabel(\"Theoretical CDF\")\n",
    "\n",
    "handles, labels = axs[0].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, title=\"Dimensions\", ncols=5, loc=\"lower center\", bbox_to_anchor=(0.5, -0.05))\n",
    "fig.savefig(\"figures_rerun/uncertainty_pp_plots.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rosenbrock p-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = []\n",
    "for k, v in baseline_rosenbrock_results.items():\n",
    "    df_tmp = pd.DataFrame({\n",
    "        \"dims\": k * np.ones(len(v)),\n",
    "        \"p_value\": v[\"p_value\"]\n",
    "    })\n",
    "    frames.append(df_tmp)\n",
    "df = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sns.plotting_context(\n",
    "    rc={\n",
    "        \"xtick.top\": False,\n",
    "    }\n",
    "), sns.axes_style(\"ticks\"):\n",
    "    g = sns.FacetGrid(df, row=\"dims\", aspect=3, height=1)\n",
    "    bins = np.linspace(0, 1.0, 8)\n",
    "    g.map_dataframe(\n",
    "        sns.histplot, x=\"p_value\", fill=True, alpha=1, element=\"step\", clip_on=False,\n",
    "        bins=bins, hue=\"dims\", hue_norm=(0, 10), palette=\"RdYlBu\",\n",
    "#         histtype=\"step\", range=[0, 1],\n",
    "#         hist_kws={\"range\": [0,1]}\n",
    "    )\n",
    "#     g.map(plt.axhline, y=0, lw=2, clip_on=False)\n",
    "# g.fig.subplots_adjust(hspace=-.5)\n",
    "axes = g.axes.flatten()\n",
    "\n",
    "for dims, ax in zip([2, 4, 8], axes):\n",
    "    ax.text(0.65, .6, f\"{dims}-dimensional\", fontweight=\"bold\", color=None, ha=\"left\", va=\"center\", transform=ax.transAxes)\n",
    "    ax.set_ylabel(\"\")\n",
    "\n",
    "axes[-1].set_xlabel(\"$p$-value\")\n",
    "    \n",
    "# g.map(label, \"dims\")\n",
    "\n",
    "g.set_titles(\"\")\n",
    "g.set(yticks=[])\n",
    "g.despine(left=True, bottom=False)\n",
    "g.tight_layout()\n",
    "\n",
    "g.fig.subplots_adjust(hspace=0.1)\n",
    "g.savefig(\"figures/rosenbrock_p_values.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Nessai INS Paper",
   "language": "python",
   "name": "nessai-ins-paper"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

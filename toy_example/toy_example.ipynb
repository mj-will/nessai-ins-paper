{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toy example\n",
    "\n",
    "Code for the toy example in \"Importance nested sampling with normalising flows\". Produces all of the relevant plots and results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from scipy.special import logsumexp\n",
    "from scipy import optimize\n",
    "import seaborn as sns\n",
    "\n",
    "basedir = \"../\"\n",
    "sys.path.append(basedir)\n",
    "from utils import configure_plotting\n",
    "\n",
    "configure_plotting(basedir)\n",
    "np.random.seed(1234)\n",
    "\n",
    "plt.rcParams[\"text.usetex\"] = True\n",
    "\n",
    "figsize = plt.rcParams['figure.figsize']\n",
    "double_figsize = (2.0 * figsize[0], figsize[1])\n",
    "\n",
    "os.makedirs(\"figures\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian prior standard deviation\n",
    "prior_std = 2.0\n",
    "# Gaussian likelihood standard deviation\n",
    "likelihood_std = 1.0\n",
    "# Number of dimensions\n",
    "dims = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the posterior standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_std = np.sqrt(1 / ((1 / prior_std ** 2) + (1 / likelihood_std ** 2)))\n",
    "print(f\"Posterior standard deviation: {post_std:.8f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the distributions using scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_dist = stats.multivariate_normal(\n",
    "    mean=np.zeros(dims),\n",
    "    cov=prior_std ** 2 * np.eye(dims)\n",
    ")\n",
    "likelihood_dist = stats.multivariate_normal(\n",
    "    mean=np.zeros(dims),\n",
    "    cov=likelihood_std ** 2 * np.eye(dims)\n",
    ")\n",
    "post_dist = stats.multivariate_normal(\n",
    "    mean=np.zeros(dims),\n",
    "    cov=post_std ** 2 * np.eye(dims)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The product of two Gaussian PDFs is proportional to another Gaussian where the scaling factor is another Gaussian evaluated at $\\mu_1$\n",
    "\n",
    "$$\n",
    "\\mathcal{N}(x=\\mu_1; \\mu_2, \\sqrt(\\sigma_1^2 + \\sigma_2^2)).\n",
    "$$\n",
    "\n",
    "Thus the evidence is this scaling factor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_evidence = stats.multivariate_normal(np.zeros(dims), prior_std ** 2 + likelihood_std ** 2).pdf(0)\n",
    "print(f\"True evidence: {true_evidence}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Posterior distribution $p(ln \\mathcal{L})$\n",
    "\n",
    "Determine the posterior define in terms of $\\lambda = \\ln \\mathcal{L}$.\n",
    "\n",
    "Start by checking the distributions of the radius and radius squared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_dist = stats.chi2(df=dims, scale=post_std ** 2)\n",
    "r_dist = stats.chi(df=dims, scale=post_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_samples = post_dist.rvs(size=100_000)\n",
    "post_r2 = np.sum(post_samples ** 2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_vec = np.linspace(0, 16, 1000)\n",
    "r_vec = np.linspace(0, 8, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, sharey=True)\n",
    "axs[0].hist(np.sqrt(post_r2), 100, density=True, histtype=\"step\")\n",
    "axs[0].plot(r_vec, r_dist.pdf(r_vec))\n",
    "axs[0].set_xlabel(r\"$r$\")\n",
    "\n",
    "axs[1].hist(post_r2, 100, density=True, histtype=\"step\")\n",
    "axs[1].plot(r2_vec, r2_dist.pdf(r2_vec))\n",
    "axs[1].set_xlabel(r\"$r^2$\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions for converting from log-likelihood ($\\lambda$) to radius $r^2$\n",
    "\n",
    "The equations are:\n",
    "\n",
    "$$\n",
    "r^2 = -2 \\sigma^2 \\left[\\frac{1}{2} \\ln(2 \\pi \\sigma) + \\lambda \\right]\n",
    "$$\n",
    "\n",
    "then \n",
    "$$\n",
    "p(\\lambda) = p(r^2) \\left| \\frac{\\partial r^2}{\\partial \\lambda}\\right|\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\n",
    "p(r^2) = \\frac{1}{2^{k/2}\\Gamma(k/2)} x^{k/2 - 1} e^{-x/2} \n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lambda_to_radius2(l, var, n):\n",
    "    return -2 * var * (0.5 * n * np.log(2 * np.pi * var) + l)\n",
    "\n",
    "def radius2_to_lambda(r2, var, n):\n",
    "    return -0.5 * (n * np.log(2 * np.pi * var) - r2 / var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_lambda(n, var):\n",
    "    return (-n / 2) * np.log(2 * np.pi * var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_samples = prior_dist.rvs(10_000)\n",
    "prior_ll = likelihood_dist.logpdf(prior_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_ll = likelihood_dist.logpdf(post_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_recon = lambda_to_radius2(post_ll, likelihood_std ** 2, dims)\n",
    "assert np.allclose(r2_recon, post_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_vec = np.linspace(min(prior_ll.min(), post_ll.min()), max(prior_ll.max(), post_ll.max()), 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Converting from radius squared**\n",
    "\n",
    "Need the Jacobian\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\lambda}{\\partial r^2} = \\left|\\frac{1}{2\\sigma^2}\\right|\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def lambda_pdf(l):\n",
    "    return r2_dist.pdf(lambda_to_radius2(l, likelihood_std ** 2, dims)) * (2 * likelihood_std ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_pdf_values = lambda_pdf(lambda_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.hist(post_ll, 100, density=True, histtype=\"stepfilled\")\n",
    "plt.plot(lambda_vec, lambda_pdf_values)\n",
    "plt.xlabel(r\"$\\lambda$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Converting from radius**\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\lambda}{\\partial r} = \\left|\\frac{r}{\\sigma^2}\\right|\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.hist(post_ll, 100, density=True, histtype=\"stepfilled\")\n",
    "r_vec = lambda_to_radius2(lambda_vec, likelihood_std ** 2, dims) ** 0.5\n",
    "plt.plot(lambda_vec, r_dist.pdf(r_vec) * likelihood_std ** 2 / r_vec)\n",
    "plt.xlabel(r\"$\\lambda$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that both methods agree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlive = 500\n",
    "n_levels = 3 # (+1 for prior)\n",
    "rho = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_likelihood(x):\n",
    "    return likelihood_dist.logpdf(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_prior(x):\n",
    "    return prior_dist.logpdf(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_level(x, rho=0.5):\n",
    "    n_remove = int(rho * x.shape[0])\n",
    "    scale = np.std(x[n_remove:])\n",
    "    level = stats.multivariate_normal(cov=(scale ** 2) * np.eye(dims))\n",
    "    return level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_meta_proposal(levels, samples, weights=None):\n",
    "    if isinstance(samples, dict):\n",
    "        all_samples = np.concatenate([s for s in samples.values()])\n",
    "    else:\n",
    "        all_samples = samples.copy()\n",
    "    # All levels have the same number of samples, so weights are equal\n",
    "    if weights is None:\n",
    "        weights = 1 / len(levels)\n",
    "    # Initial samples are drawn from the log_prior\n",
    "    log_q_i = np.nan * np.zeros((len(all_samples), len(levels)))\n",
    "    for i, level in enumerate(levels.values()):\n",
    "        log_q_i[:, i] = level.logpdf(all_samples)\n",
    "    log_Q = logsumexp(log_q_i, b=weights, axis=1)\n",
    "    return log_Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "levels = dict()\n",
    "level_samples = dict()\n",
    "sample_log_likelihoods = dict()\n",
    "sample_log_priors = dict()\n",
    "sample_meta_proposal = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_samples(\n",
    "    level_samples,\n",
    "    sample_log_likelihoods,\n",
    "    sample_log_priors,\n",
    "    label,\n",
    "):\n",
    "    sample_log_likelihoods[label] = log_likelihood(level_samples[label])\n",
    "    sample_log_priors[label] = log_prior(level_samples[label])\n",
    "    sorted_idx = np.argsort(sample_log_likelihoods[label])\n",
    "    level_samples[label] = level_samples[label][sorted_idx]\n",
    "    sample_log_priors[label] = sample_log_priors[label][sorted_idx]\n",
    "    sample_log_likelihoods[label] = sample_log_likelihoods[label][sorted_idx]\n",
    "    return (\n",
    "        level_samples,\n",
    "        sample_log_likelihoods,\n",
    "        sample_log_priors,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = '-1'\n",
    "levels[label] = prior_dist\n",
    "level_samples[label] = prior_dist.rvs(size=nlive)\n",
    "level_samples, sample_log_likelihoods, sample_log_priors = update_samples(\n",
    "    level_samples, sample_log_likelihoods, sample_log_priors, label\n",
    ")\n",
    "\n",
    "\n",
    "for n in range(n_levels):\n",
    "    previous = str(n - 1)\n",
    "    label = str(n)\n",
    "    levels[label] = construct_level(level_samples[previous], rho=rho)\n",
    "    level_samples[label] = levels[label].rvs(size=nlive)\n",
    "    level_samples, sample_log_likelihoods, sample_log_priors = update_samples(\n",
    "        level_samples, sample_log_likelihoods, sample_log_priors, label\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_samples = np.concatenate([s for s in level_samples.values()], axis=0)\n",
    "final_log_l = log_likelihood(final_samples)\n",
    "final_log_p = log_prior(final_samples)\n",
    "final_log_q = log_meta_proposal(levels, final_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_posterior_weights = final_log_l + final_log_p - final_log_q\n",
    "post_weights = np.exp(log_posterior_weights)\n",
    "post_weights /= np.sum(post_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_level_log_likelihood(d):\n",
    "    fig = plt.figure()\n",
    "    colours = plt.cm.viridis(np.linspace(0, 1, len(d)))\n",
    "    for logL, c in zip(d.values(), colours):\n",
    "        plt.hist(logL, color=c, histtype='step', lw=2.0, density=True)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axd = plt.subplot_mosaic(\n",
    "    [[\"upper\", \"upper\"], [\"lower_left\", \"lower_right\"]],\n",
    "    figsize=(figsize[0], 1.5 * figsize[1]),\n",
    "#     sharey=,\n",
    ")\n",
    "colours = plt.cm.viridis(np.linspace(0, 1, len(levels)))\n",
    "\n",
    "print(list(axd.keys()))\n",
    "\n",
    "for i, ls in enumerate(level_samples.values()):\n",
    "    axd[\"upper\"].scatter(ls[:, 0], ls[:, 1], s=1, color=\"silver\")\n",
    "theta = np.linspace(0, 2 * np.pi, 1000)\n",
    "for i, level in enumerate(levels.values()):\n",
    "    r = np.sqrt(np.diag(level.cov))[0]\n",
    "    axd[\"upper\"].plot(r * np.cos(theta), r * np.sin(theta), c=colours[i], ls='-')\n",
    "r_post = np.sqrt(np.diag(post_dist.cov))[0]\n",
    "axd[\"upper\"].plot(r_post * np.cos(theta), r_post * np.sin(theta), c=\"C1\", ls='--')\n",
    "axd[\"upper\"].set_xlabel(r\"$\\theta_0$\")\n",
    "axd[\"upper\"].set_ylabel(r\"$\\theta_1$\")\n",
    "axd[\"upper\"].set_xlim([-4, 4])\n",
    "axd[\"upper\"].set_ylim([-4, 4])\n",
    "axd[\"upper\"].set_aspect('equal', adjustable='box')\n",
    "\n",
    "post_range = [-15, final_log_l.max()]\n",
    "post_range = [-15, 0]\n",
    "\n",
    "bins = np.linspace(post_range[0], post_range[1], 32)\n",
    "for i, logL in enumerate(sample_log_likelihoods.values()):\n",
    "    axd[\"lower_left\"].hist(logL, bins=bins, color=colours[i], histtype='step', density=True)\n",
    "# axs[1].plot(lambda_vec, lambda_pdf, c='C1', lw=2.0, ls='--')\n",
    "axd[\"lower_left\"].set_xlabel(r\"$\\ln \\mathcal{L}$\")\n",
    "axd[\"lower_left\"].set_ylabel(r\"$p(\\ln \\mathcal{L})$\")\n",
    "axd[\"lower_left\"].set_xlim(post_range)\n",
    "# axs[1].set_yscale(\"log\")\n",
    "\n",
    "# post_range = [-20, final_log_l.max()]\n",
    "axd[\"lower_right\"].hist(\n",
    "    final_log_l, 50, density=True, weights=post_weights, histtype=\"stepfilled\",\n",
    "    range=post_range, color=colours[1]\n",
    ")\n",
    "axd[\"lower_right\"].plot(lambda_vec, lambda_pdf_values, c='C1', ls='--')\n",
    "axd[\"lower_right\"].set_xlim(post_range)\n",
    "axd[\"lower_right\"].set_xlabel(r\"$\\ln \\mathcal{L}$\")\n",
    "# axd[\"lower_right\"].set_ylabel(r\"$p(\\ln \\mathcal{L})$\")\n",
    "\n",
    "# axd[\"lower_right\"].set_yticklabels([])\n",
    "axd[\"lower_left\"].sharey(axd[\"lower_right\"])\n",
    "plt.setp(axd[\"lower_right\"].get_yticklabels(), visible=False)\n",
    "\n",
    "# axd[\"lower_right\"].set_yticks(axd[\"lower_right\"].get_yticks())\n",
    "# axs[2].set_yscale(\"log\")\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.savefig(\"figures/toy_example.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evidence(log_likelihood, log_prior, log_meta_proposal):\n",
    "    return np.exp(logsumexp(log_likelihood + log_prior - log_meta_proposal)) / len(log_likelihood)\n",
    "\n",
    "\n",
    "def evidence_error(log_likelihood, log_prior, log_meta_proposal):\n",
    "    n = len(log_likelihood)\n",
    "    z = evidence(log_likelihood, log_prior, log_meta_proposal)\n",
    "    return (1 / (n * (n - 1))) * np.sum(\n",
    "        (np.exp(log_likelihood + log_prior - log_meta_proposal) - z) ** 2.0,\n",
    "        axis=-1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_hat = evidence(final_log_l, final_log_p, final_log_q)\n",
    "Z_hat_sigma = np.sqrt(evidence_error(final_log_l, final_log_p, final_log_q))\n",
    "print(f\"Final estimate: {Z_hat} +/- {Z_hat_sigma}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Nessai INS Paper",
   "language": "python",
   "name": "nessai-ins-paper"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "cf60c25e2f22be530508d4d3f1d8ebde93d98a56e32fafe695a7f73cef43c80d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "basedir = \"../../\"\n",
    "sys.path.append(basedir)\n",
    "from utils import configure_plotting, load_json\n",
    "\n",
    "configure_plotting(basedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_pool = [1, 2, 4, 8, 16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_results = {}\n",
    "_baseline_results = {}\n",
    "for p in n_pool:\n",
    "    path = os.path.join(f\"n_pool_{p}\", \"result\", \"*_nessai/result.json\")\n",
    "    print(path)\n",
    "    files = glob.glob(path)\n",
    "    print(f\"Found {len(files)} files\")\n",
    "    _results[p] = [load_json(f) for f in files]\n",
    "    path = os.path.join(f\"n_pool_{p}_baseline\", \"result\", \"*_nessai/result.json\")\n",
    "    print(path)\n",
    "    files = glob.glob(path)\n",
    "    print(f\"Found {len(files)} files\")\n",
    "    _baseline_results[p] = [load_json(f) for f in files]\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time(string):\n",
    "    t = datetime.datetime.strptime(string, \"%H:%M:%S.%f\") - datetime.datetime(\n",
    "        1900, 1, 1\n",
    "    )\n",
    "    return t.total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = dict(\n",
    "    sampling_time=None,\n",
    "    add_samples_time=None,\n",
    "    update_level_time=None,\n",
    "    update_ns_time=None,\n",
    "    redraw_time=None,\n",
    "    likelihood_evaluation_time=None,\n",
    ")\n",
    "baseline_results = dict(\n",
    "    sampling_time=None,\n",
    "    likelihood_evaluation_time=None,\n",
    "    training_time=None,\n",
    "    population_time=None,\n",
    ")\n",
    "for r, _r in [(results, _results), (baseline_results, _baseline_results)]:\n",
    "    for k in r.keys():\n",
    "        if r[k] is None:\n",
    "            r[k] = pd.DataFrame(columns=[\"mean\", \"std\"])\n",
    "        for res in _r.values():\n",
    "            try:\n",
    "                dd = dict(\n",
    "                    mean=np.nanmean([d[k] for d in res]) / 60,\n",
    "                    std=np.nanstd([d[k] for d in res]) / 60,\n",
    "                )\n",
    "            except TypeError:\n",
    "                get_time(res[0][k])\n",
    "                dd = dict(\n",
    "                    mean=np.nanmean([get_time(d[k]) for d in res]) / 60,\n",
    "                    std=np.nanstd([get_time(d[k]) for d in res]) / 60,\n",
    "                )\n",
    "            r[k] = r[k].append(dd, ignore_index=True)\n",
    "#             r[k] = pd.concat([r[k], pd.DataFrame(dd)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_results[\"population_time\"] = (\n",
    "    baseline_results[\"population_time\"] - baseline_results[\"likelihood_evaluation_time\"]\n",
    ")\n",
    "results[\"add_samples_time\"] = (\n",
    "    results[\"add_samples_time\"] - results[\"likelihood_evaluation_time\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "likelihood_fraction = results[\"likelihood_evaluation_time\"][\"mean\"] / (results[\"sampling_time\"][\"mean\"] + results[\"redraw_time\"][\"mean\"])\n",
    "print(f\"Fraction of time spent evaluating the likelihood: {likelihood_fraction}\")\n",
    "print(1 - likelihood_fraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "likelihood_fraction = baseline_results[\"likelihood_evaluation_time\"][\"mean\"] / (baseline_results[\"sampling_time\"][\"mean\"] )\n",
    "print(f\"Fraction of time spent evaluating the likelihood: {likelihood_fraction}\")\n",
    "print(1 - likelihood_fraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_labels = dict(\n",
    "    sampling_time=\"Total\",\n",
    "    add_samples_time=\"Adding samples\",\n",
    "    redraw_time=\"Resampling\",\n",
    "    update_level_time=\"Training\",\n",
    "    update_ns_time=\"Meta-proposal\",\n",
    "    likelihood_evaluation_time=\"Likelihood\",\n",
    "    training_time=\"Training\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(dpi=200)\n",
    "hatch = [\"/\", \"\\\\\", \"|\", \".\", \"x\", \"x\", \"o\", \"O\", \".\", \"*\"]\n",
    "xloc = np.arange(len(n_pool))\n",
    "width = 0.4\n",
    "sep = width / 2\n",
    "order = [\n",
    "    \"update_level_time\",\n",
    "    \"likelihood_evaluation_time\",\n",
    "]\n",
    "base_order = [\"training_time\", \"likelihood_evaluation_time\"]#, \"population_time\"]\n",
    "colours = sns.color_palette(\"RdYlBu\", n_colors=7)\n",
    "baseline_colours = [colours[-1], colours[-2], colours[-3]]\n",
    "ins_colours = colours\n",
    "bottom = np.zeros_like(n_pool)\n",
    "\n",
    "\n",
    "plt.errorbar(\n",
    "    xloc - sep, baseline_results[\"sampling_time\"][\"mean\"],\n",
    "    yerr=baseline_results[\"sampling_time\"][\"std\"],\n",
    "    ls='', marker='x', color=baseline_colours[0], label=r\"Total\"\n",
    ")\n",
    "other_height = (\n",
    "    baseline_results[\"sampling_time\"][\"mean\"]\n",
    "    - baseline_results[\"likelihood_evaluation_time\"][\"mean\"]\n",
    "    - baseline_results[\"training_time\"][\"mean\"]\n",
    ")\n",
    "base_bottom = np.zeros_like(n_pool)\n",
    "plt.bar(\n",
    "        xloc - sep,\n",
    "        other_height,\n",
    "        bottom=base_bottom,\n",
    "        label=\"Other\",\n",
    "        linewidth=0.0,\n",
    "        width=width,\n",
    "#         hatch=\"...\",\n",
    "        facecolor=baseline_colours[0],\n",
    "    )\n",
    "base_bottom += other_height\n",
    "\n",
    "for i, k in enumerate(base_order):\n",
    "    base_res = baseline_results[k]\n",
    "    height = base_res[\"mean\"] #/ baseline_results[\"sampling_time\"][\"mean\"]\n",
    "    plt.bar(\n",
    "        xloc - sep,\n",
    "        height,\n",
    "        bottom=base_bottom,\n",
    "        label=bar_labels.get(k),\n",
    "        linewidth=0.0,\n",
    "        width=width,\n",
    "#         hatch=\"...\",\n",
    "        facecolor=baseline_colours[i + 1],\n",
    "    )\n",
    "\n",
    "    base_bottom = base_bottom + height\n",
    "\n",
    "\n",
    "total_error = np.sqrt(np.array(results[\"sampling_time\"][\"std\"].to_numpy() ** 2.0 + results[\"redraw_time\"][\"std\"].to_numpy() ** 2.0, dtype=float))\n",
    "plt.errorbar(\n",
    "    xloc + sep, results[\"sampling_time\"][\"mean\"] + results[\"redraw_time\"][\"mean\"],\n",
    "    yerr=total_error,\n",
    "    ls='', marker='.', color=ins_colours[0], label=r\"Total\"\n",
    ")\n",
    "\n",
    "other_height = (\n",
    "    results[\"sampling_time\"][\"mean\"]\n",
    "    + results[\"redraw_time\"][\"mean\"]\n",
    "    - results[\"update_level_time\"][\"mean\"]\n",
    "    - results[\"likelihood_evaluation_time\"][\"mean\"]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "hatch = [\"//\", r\"\\\\\", \"||\"][::-1]\n",
    "plt.bar(\n",
    "        xloc + sep,\n",
    "        other_height,\n",
    "        bottom=bottom,\n",
    "        label=\"Other\",\n",
    "        linewidth=0.0,\n",
    "        width=width,\n",
    "        facecolor=ins_colours[0],\n",
    "#         edgecolor=ins_colours[2],\n",
    "        hatch=hatch[0],\n",
    "    )\n",
    "bottom += other_height\n",
    "for i, k in enumerate(order):\n",
    "    res = results[k]\n",
    "    height = res[\"mean\"] #/ (\n",
    "#         results[\"sampling_time\"][\"mean\"] + results[\"redraw_time\"][\"mean\"]\n",
    "#     )\n",
    "    plt.bar(\n",
    "        xloc + sep,\n",
    "        height,\n",
    "        bottom=bottom,\n",
    "        label=bar_labels.get(k),\n",
    "        linewidth=0.0,\n",
    "        width=width,\n",
    "        facecolor=ins_colours[i + 1],\n",
    "#         edgecolor=ins_colours[i],\n",
    "        hatch=hatch[i + 1],\n",
    "        fill=True,\n",
    "    )\n",
    "    bottom = bottom + height\n",
    "    \n",
    "\n",
    "plt.ylabel(\"Wall time [min]\")\n",
    "plt.xlabel(\"Number of cores\")\n",
    "plt.xticks(xloc, labels=n_pool)\n",
    "plt.tick_params(which=\"minor\", top=False, bottom=False)\n",
    "\n",
    "handles, _ = plt.gca().get_legend_handles_labels()\n",
    "\n",
    "\n",
    "\n",
    "base_handles, ins_handles = handles[:4], handles[4:]\n",
    "labels = [\"Total\", \"Likelihood\", \"Training\", \"Other\"]\n",
    "\n",
    "print(base_handles, ins_handles)\n",
    "\n",
    "base_handles = [base_handles[0]] + base_handles[1:][::-1]\n",
    "ins_handles = [ins_handles[0]] + ins_handles[1:][::-1]\n",
    "\n",
    "title_handle = matplotlib.patches.Rectangle((0,0), 1, 1, fill=False, edgecolor='none',\n",
    "                                 visible=False)\n",
    "handles = (\n",
    "    [title_handle]\n",
    "    + base_handles\n",
    "    +[title_handle]\n",
    "    + ins_handles\n",
    ")\n",
    "labels = (\n",
    "    [r\"\\texttt{nessai}\"]\n",
    "    + labels\n",
    "    +[r\"\\texttt{i-nessai}\"]\n",
    "    + labels\n",
    ")\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.legend(handles=handles, labels=labels, loc=\"upper right\", ncol=2)\n",
    "fig.savefig(\"figures/parallelisation.pdf\", bbox_inches=\"tight\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Nessai INS Paper",
   "language": "python",
   "name": "nessai-ins-paper"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
